{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fSXBe1XZyGi"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "import tensorflow as tf\n",
        "print(\"GPU visível p/ TF:\", tf.config.list_physical_devices(\"GPU\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "URL = \"https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\"\n",
        "ZIP = Path(\"/content/catsdogs.zip\")\n",
        "RAW = Path(\"/content/catsdogs_raw\")\n",
        "\n",
        "if not ZIP.exists():\n",
        "    print(\"Baixando…\")\n",
        "    with requests.get(URL, headers={\"User-Agent\":\"Mozilla/5.0\"}, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(ZIP, \"wb\") as f:\n",
        "            for chunk in r.iter_content(1024*1024):\n",
        "                if chunk: f.write(chunk)\n",
        "\n",
        "if not RAW.exists():\n",
        "    print(\"Extraindo…\")\n",
        "    with zipfile.ZipFile(ZIP, \"r\") as z:\n",
        "        z.extractall(RAW)\n",
        "\n",
        "print(\"OK:\", RAW.exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzToBJ1zatA5",
        "outputId": "2c294f44-12cc-4e1b-c8ad-9bdb39b3e32b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando…\n",
            "Extraindo…\n",
            "OK: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import random, shutil\n",
        "\n",
        "SRC  = Path(\"/content/catsdogs_raw/PetImages\")\n",
        "ROOT = Path(\"/content/data\")\n",
        "for s in (\"train\",\"val\",\"test\"):\n",
        "    for c in (\"Cat\",\"Dog\"):\n",
        "        (ROOT/s/c).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def is_ok(p: Path):\n",
        "    try:\n",
        "        with Image.open(p) as im: im.verify()\n",
        "        return True\n",
        "    except: return False\n",
        "\n",
        "def split_copy(cls: str):\n",
        "    files = list((SRC/cls).glob(\"*.jpg\"))\n",
        "    files = [f for f in files if f.stat().st_size > 0 and is_ok(f)]\n",
        "    random.seed(42); random.shuffle(files)\n",
        "    n = len(files); n_tr = int(0.70*n); n_val = int(0.15*n)\n",
        "    tr, va, te = files[:n_tr], files[n_tr:n_tr+n_val], files[n_tr+n_val:]\n",
        "    for f in tr: shutil.copy2(f, ROOT/\"train\"/cls/f.name)\n",
        "    for f in va: shutil.copy2(f, ROOT/\"val\"/cls/f.name)\n",
        "    for f in te: shutil.copy2(f, ROOT/\"test\"/cls/f.name)\n",
        "    return len(tr), len(va), len(te)\n",
        "\n",
        "print(\"Cat:\", split_copy(\"Cat\"))\n",
        "print(\"Dog:\", split_copy(\"Dog\"))\n",
        "print(\"Base:\", ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot4S6Vqta66T",
        "outputId": "0e968494-29c9-471c-bcbd-82bd573be7ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat: (8749, 1874, 1876)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dog: (8749, 1874, 1876)\n",
            "Base: /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH = 32  # se a GPU lotar, reduza para 16\n",
        "\n",
        "def _parse(path: tf.Tensor):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)   # força 3 canais\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = preprocess_input(img)\n",
        "    is_cat = tf.strings.regex_full_match(path, \".*/Cat/.*\")\n",
        "    label = tf.where(is_cat, 0, 1)\n",
        "    label = tf.one_hot(label, 2)\n",
        "    return img, label\n",
        "\n",
        "def make_ds(pattern, shuffle=True):\n",
        "    ds = tf.data.Dataset.list_files(pattern, shuffle=shuffle)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(50_000, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.apply(tf.data.experimental.ignore_errors())\n",
        "    ds = ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train = make_ds(\"/content/data/train/*/*.jpg\", shuffle=True)\n",
        "val   = make_ds(\"/content/data/val/*/*.jpg\",   shuffle=False)\n",
        "test  = make_ds(\"/content/data/test/*/*.jpg\",  shuffle=False)\n",
        "\n",
        "xb, yb = next(iter(train))\n",
        "print(\"Batch:\", xb.shape, yb.shape)  # ex.: (32, 224, 224, 3) (32, 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Ipt2FNbGtz",
        "outputId": "cca6d155-292d-49a4-880f-57e8628a3bce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-1480336748.py:23: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: (32, 224, 224, 3) (32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Base pré-treinada\n",
        "base = keras.applications.VGG16(include_top=False, weights=\"imagenet\",\n",
        "                                input_shape=(224,224,3))\n",
        "base.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(224,224,3))\n",
        "x = base(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.5, verbose=1),\n",
        "]\n",
        "\n",
        "print(\"Treinando (base congelada)…\")\n",
        "history = model.fit(train, validation_data=val, epochs=5, callbacks=callbacks)\n",
        "\n",
        "print(\"Teste (congelada):\")\n",
        "model.evaluate(test, verbose=2)\n",
        "\n",
        "# Fine-tuning: liberar só o bloco 5 da VGG16\n",
        "for layer in base.layers:\n",
        "    layer.trainable = layer.name.startswith(\"block5\")\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Treinando (fine-tuning)…\")\n",
        "history_ft = model.fit(train, validation_data=val, epochs=3, callbacks=callbacks)\n",
        "\n",
        "print(\"Teste (fine-tuning):\")\n",
        "model.evaluate(test, verbose=2)\n",
        "\n",
        "# Relatório final\n",
        "y_true, y_pred = [], []\n",
        "for xb, yb in test:\n",
        "    pr = model.predict(xb, verbose=0)\n",
        "    y_true.extend(np.argmax(yb.numpy(), axis=1))\n",
        "    y_pred.extend(np.argmax(pr, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Cat\",\"Dog\"]))\n",
        "print(\"Matriz de confusão:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR9t7EU8bObc",
        "outputId": "ba06ed85-2b2c-4c4c-d666-614f2201ab48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Treinando (base congelada)…\n",
            "Epoch 1/5\n",
            "    543/Unknown \u001b[1m124s\u001b[0m 200ms/step - accuracy: 0.8526 - loss: 1.2011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 247ms/step - accuracy: 0.8527 - loss: 1.1998 - val_accuracy: 0.9796 - val_loss: 0.0976 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 214ms/step - accuracy: 0.9708 - loss: 0.1314 - val_accuracy: 0.9820 - val_loss: 0.0770 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9784 - loss: 0.0829\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 214ms/step - accuracy: 0.9784 - loss: 0.0829 - val_accuracy: 0.9804 - val_loss: 0.0780 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 213ms/step - accuracy: 0.9805 - loss: 0.0716 - val_accuracy: 0.9839 - val_loss: 0.0577 - learning_rate: 5.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9820 - loss: 0.0639\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 214ms/step - accuracy: 0.9820 - loss: 0.0639 - val_accuracy: 0.9836 - val_loss: 0.0594 - learning_rate: 5.0000e-04\n",
            "Teste (congelada):\n",
            "117/117 - 30s - 256ms/step - accuracy: 0.9799 - loss: 0.0866\n",
            "Treinando (fine-tuning)…\n",
            "Epoch 1/3\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 254ms/step - accuracy: 0.9583 - loss: 0.1625 - val_accuracy: 0.9798 - val_loss: 0.0607 - learning_rate: 1.0000e-04\n",
            "Epoch 2/3\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 332ms/step - accuracy: 0.9873 - loss: 0.0356 - val_accuracy: 0.9820 - val_loss: 0.0519 - learning_rate: 1.0000e-04\n",
            "Epoch 3/3\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 246ms/step - accuracy: 0.9919 - loss: 0.0252 - val_accuracy: 0.9890 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
            "Teste (fine-tuning):\n",
            "117/117 - 21s - 183ms/step - accuracy: 0.9810 - loss: 0.0592\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.98      0.98      0.98      1865\n",
            "         Dog       0.98      0.98      0.98      1865\n",
            "\n",
            "    accuracy                           0.98      3730\n",
            "   macro avg       0.98      0.98      0.98      3730\n",
            "weighted avg       0.98      0.98      0.98      3730\n",
            "\n",
            "Matriz de confusão:\n",
            " [[1834   31]\n",
            " [  40 1825]]\n"
          ]
        }
      ]
    }
  ]
}
